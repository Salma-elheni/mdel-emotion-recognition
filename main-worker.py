import tensorflow as tf  # Pour utiliser le mod√®le de deep learning
from tensorflow.keras.models import load_model  # Pour charger un mod√®le entra√Æn√©
import numpy as np  # Pour les op√©rations sur les tableaux
import cv2  # Pour le traitement d‚Äôimage
import os  # Pour parcourir les fichiers et dossiers
import time  # Pour mesurer le temps d'ex√©cution
import threading  # Pour le multithreading
from queue import Queue  # File de t√¢ches thread-safe
from collections import Counter, defaultdict  # Pour compter les √©motions

# Liste des √©motions possibles que le mod√®le peut pr√©dire
CLASS_LABELS = ['Anger', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sadness', "Surprise"]
# Emoji associ√© √† chaque √©motion
CLASS_LABELS_EMOJIS = ["üëø", "ü§¢", "üò±", "üòä", "üòê", "üòî", "üò≤"]

# Variable globale pour stocker le mod√®le et un verrou pour √©viter les conflits entre threads
model = None
model_lock = threading.Lock()

# Fonction pour charger le mod√®le une seule fois (prot√©g√©e par un verrou)
def load_model_once(model_path):
    global model
    with model_lock:
        if model is None:
            model = load_model(model_path)

# Fonction de pr√©traitement d'image avant de la passer au mod√®le
def preprocess_image(image_path):
    img = cv2.imread(image_path, cv2.IMREAD_REDUCED_GRAYSCALE_2)  # Lecture de l'image en niveaux de gris
    img = cv2.resize(img, (48, 48))  # Redimensionnement √† 48x48 pixels (taille attendue par le mod√®le)
    img = cv2.equalizeHist(img)  # am√©liorer le contraste
    img = cv2.GaussianBlur(img, (3, 3), 0)  # Flou l√©ger pour r√©duire le bruit
    # Filtre pour renforcer les contours (nettet√©)
    sharpening_kernel = np.array([[0, -1, 0],
                                  [-1, 5, -1],
                                  [0, -1, 0]])
    img = cv2.filter2D(img, -1, sharpening_kernel)
    img = img.astype('float32') / 255.0  # Normalisation des pixels entre 0 et 1
    img = np.expand_dims(img, axis=0)  # Ajout de la dimension batch
    img = np.expand_dims(img, axis=-1)  # Ajout de la dimension channel
    return img

# Pr√©diction de l‚Äô√©motion pour une image donn√©e
def predict_emotion(image_path):
    img = preprocess_image(image_path)  # Pr√©traitement
    prediction = model.predict(img, verbose=0)  # Pr√©diction avec le mod√®le
    emotion_index = np.argmax(prediction)  # Index de l‚Äô√©motion pr√©dite
    return CLASS_LABELS[emotion_index], CLASS_LABELS_EMOJIS[emotion_index]  # √âmotion + emoji associ√©

# Fonction ex√©cut√©e par chaque thread pour traiter les images
def worker(task_queue, results, counter_dict, lock, model_path, image_count_by_thread):
    thread_name = threading.current_thread().name  # Nom du thread en cours
    local_model = load_model(model_path)  # Chaque thread charge sa propre copie du mod√®le

    global model
    with model_lock:
        model = local_model  # D√©finir le mod√®le global utilis√© dans predict_emotion()

    while True:
        image_path = task_queue.get()  # R√©cup√®re une image √† traiter
        if image_path is None:
            break  # Fin du traitement pour ce thread

        start = time.time()  # D√©but du chrono
        emotion, emoji = predict_emotion(image_path)  # Pr√©diction
        duration = time.time() - start  # Temps pris pour traiter l'image

        with lock:  # Acc√®s aux structures partag√©es
            folder = os.path.basename(os.path.dirname(image_path))  # Nom du dossier de l'image
            if folder not in counter_dict:
                counter_dict[folder] = Counter()
            counter_dict[folder][emotion] += 1  # Incr√©mentation du compteur d‚Äô√©motions
            results.append((image_path, emotion, emoji))  # Stockage du r√©sultat
            image_count_by_thread[thread_name] += 1  # Compteur d‚Äôimages trait√©es par ce thread

        print(f"[{thread_name}] finished {os.path.basename(image_path)} in {duration:.2f} sec")

# Fonction principale qui g√®re le traitement multithread√©
def predict_emotions_threaded(parent_folder):
    start_time = time.time()  # D√©but du chrono global
    all_image_paths = []  # Liste de toutes les images

    # Parcours des sous-dossiers pour r√©cup√©rer les chemins des images
    for subfolder in os.listdir(parent_folder):
        subfolder_path = os.path.join(parent_folder, subfolder)
        if os.path.isdir(subfolder_path):
            for root, _, files in os.walk(subfolder_path):
                for file in files:
                    if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                        all_image_paths.append(os.path.join(root, file))

    image_queue = Queue()  # File de t√¢ches
    for path in all_image_paths:
        image_queue.put(path)  # Ajout de chaque image √† la file

    num_threads = min(os.cpu_count() - 1, len(all_image_paths))  # Choix du nombre optimal de threads

    results = []  # Stockage des r√©sultats (image, label, emoji)
    emotion_counts = {}  # Compteur d‚Äô√©motions par dossier
    lock = threading.Lock()  # Verrou partag√© pour synchroniser les acc√®s
    model_path = './cnn_emotion_detection.h5'  # Chemin vers le mod√®le
    image_count_by_thread = defaultdict(int)  # Nombre d'images trait√©es par thread

    threads = []  # Liste des threads
    for _ in range(num_threads):
        t = threading.Thread(
            target=worker,
            args=(image_queue, results, emotion_counts, lock, model_path, image_count_by_thread)
        )
        t.start()
        threads.append(t)

    for _ in threads:
        image_queue.put(None)  # Envoi du signal de fin √† chaque thread

    for t in threads:
        t.join()  # Attente de la fin de tous les threads

    total_time = time.time() - start_time  # Temps total de traitement
    print(f"\n‚úÖ Total execution time: {total_time:.2f} sec ({int(total_time // 60)} min)")

    print("\nüìä Images processed per thread:")
    for thread_name, count in image_count_by_thread.items():
        print(f"  {thread_name}: {count} images")

    print("\nüìÅ Emotion counts per folder:")
    for folder, counter in emotion_counts.items():
        print(f"\n{folder}:")
        for emotion, count in counter.items():
            print(f"  {emotion}: {count}")

    return results  # Retourne tous les r√©sultats

# Point d‚Äôentr√©e du programme
if __name__ == "__main__":
    folder_path = "./test_images"  # Chemin vers le dossier √† analyser
    results = predict_emotions_threaded(folder_path)  # Lancement du traitement

    # Sauvegarde des r√©sultats dans un fichier texte
    with open("emotion_results.txt", "w", encoding="utf-8") as f:
        for image_path, label, emoji in results:
            f.write(f"{image_path}: {label} {emoji}\n")

    print("\nüìù Results saved to 'emotion_results.txt'")
